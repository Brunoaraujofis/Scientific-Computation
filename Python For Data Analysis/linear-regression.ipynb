{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Linear Regression Basics","metadata":{}},{"cell_type":"markdown","source":"Regressão Linear (R.L) é uma técnica de modelação preditiva para prever uma variável de resposta numérica (Nº Real) baseada em uma ou mais variáveis explicativas.\n\nNo caso da Regressão Linear com uma única variável explicativa, utilizamos a combinação linear a seguir:\n\nrespose = intercept + constant x explanatory, \n\nou seja, uma equação linear (y(x) = a + bx).\n\nO modelo é construído para se ajustar a uma linha que minimize os erros ou resíduos. O resultado é buscar por um fit linear que melhor ajustam os dados. \n\nVamos construir dados que relacionam o quanto um carro gasta de combustível dependendo de seu peso (mpg x weight). \n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\nmatplotlib.style.use('ggplot')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:11:36.882030Z","iopub.execute_input":"2021-11-18T14:11:36.882387Z","iopub.status.idle":"2021-11-18T14:11:37.747044Z","shell.execute_reply.started":"2021-11-18T14:11:36.882289Z","shell.execute_reply":"2021-11-18T14:11:37.746321Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"mtcars = pd.read_csv(\"../input/mtcars/mtcars.csv\")\n\nmtcars.plot(kind = \"scatter\",\n           x = \"wt\",\n           y = \"mpg\",\n           figsize = (9,9),\n           color = \"black\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:27:29.145421Z","iopub.execute_input":"2021-11-18T14:27:29.145740Z","iopub.status.idle":"2021-11-18T14:27:29.517287Z","shell.execute_reply.started":"2021-11-18T14:27:29.145706Z","shell.execute_reply":"2021-11-18T14:27:29.516679Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"O plot dos pontos mostram que eles tem dependencias aproximadamente liner, sem apresentar muitos outliers, sugerindo que uma regressão linear funcionara bem. \n\nA lib. Scikit-learn contem um monte de funções que podem ser utilizadas em modelos preditivos, vamos importar a regressão linear dela.","metadata":{}},{"cell_type":"code","source":"from sklearn import linear_model","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:32:08.102007Z","iopub.execute_input":"2021-11-18T14:32:08.102313Z","iopub.status.idle":"2021-11-18T14:32:08.517215Z","shell.execute_reply.started":"2021-11-18T14:32:08.102284Z","shell.execute_reply":"2021-11-18T14:32:08.516089Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"regression_model = linear_model.LinearRegression() # aqui estamos começando o modelo  (Ele sempre precisa ser inicializado)\n\nregression_model.fit( X = pd.DataFrame(mtcars[\"wt\"]),\n                    y = mtcars[\"mpg\"])\n\nprint(regression_model.intercept_)\nprint(regression_model.coef_)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:36:25.975445Z","iopub.execute_input":"2021-11-18T14:36:25.975733Z","iopub.status.idle":"2021-11-18T14:36:25.983734Z","shell.execute_reply.started":"2021-11-18T14:36:25.975704Z","shell.execute_reply":"2021-11-18T14:36:25.983069Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Os outputs acima mostram que o fit que o modelo foi é:\n\n\nmpg = 37.2851261673420  -5.34447157 x wt","metadata":{}},{"cell_type":"markdown","source":"Podemos ter uma ideia do quanto a variancia  da variavel de resposta (mpg) é explicado por este fit usando model.score() function.","metadata":{}},{"cell_type":"code","source":"regression_model.score( X = pd.DataFrame(mtcars[\"wt\"]),\n                       y = mtcars[\"mpg\"]) ","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:41:29.894354Z","iopub.execute_input":"2021-11-18T14:41:29.895231Z","iopub.status.idle":"2021-11-18T14:41:29.904919Z","shell.execute_reply.started":"2021-11-18T14:41:29.895184Z","shell.execute_reply":"2021-11-18T14:41:29.904089Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Neste caso, vemos que o peso do carro explica 75% da variancia da variável de resposta (mpg). Este valor é chamado de \"R-squared\" e tem range entre 0 e 1. R-squared é baseado nos resíduos: diferenças entre o que o modelo prevê para cada ponto de dados e o valor real de cada ponto. Podemos extrair os resíduos do modelo fazendo uma previsão com o modelo sobre os dados e depois subtraindo o valor real de cada previsão","metadata":{}},{"cell_type":"code","source":"train_prediction = regression_model.predict(X = pd.DataFrame(mtcars[\"wt\"])) \n\nresiduals = mtcars[\"mpg\"] - train_prediction\nresiduals.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:53:52.930449Z","iopub.execute_input":"2021-11-18T14:53:52.930751Z","iopub.status.idle":"2021-11-18T14:53:52.944680Z","shell.execute_reply.started":"2021-11-18T14:53:52.930722Z","shell.execute_reply":"2021-11-18T14:53:52.943901Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"R-squared é calculado por 1 - SSresidual/SStoal, que serão definidos a seguir:","metadata":{}},{"cell_type":"code","source":"SSresiduals = (residuals**2).sum()\nSStotal = ((mtcars[\"mpg\"] - mtcars[\"mpg\"].mean())**2).sum()\n\nR-squared = 1 - SSresiduals/SStotal","metadata":{"execution":{"iopub.status.busy":"2021-11-18T14:56:11.336268Z","iopub.execute_input":"2021-11-18T14:56:11.336547Z","iopub.status.idle":"2021-11-18T14:56:11.345121Z","shell.execute_reply.started":"2021-11-18T14:56:11.336519Z","shell.execute_reply":"2021-11-18T14:56:11.344146Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"Vamos fazer agora um scatterplot dos dados e do modelo junto para a visualização de como este é um bom fit para os dados.","metadata":{}},{"cell_type":"code","source":"mtcars.plot(kind = \"scatter\",\n           x =  \"wt\",\n           y = \"mpg\",\n           figsize = (9,9),\n            color = \"black\",\n           xlim = (0,7))\n\nplt.plot(mtcars[\"wt\"], train_prediction, color = \"blue\")","metadata":{"execution":{"iopub.status.busy":"2021-11-18T15:16:12.218739Z","iopub.execute_input":"2021-11-18T15:16:12.219185Z","iopub.status.idle":"2021-11-18T15:16:12.547325Z","shell.execute_reply.started":"2021-11-18T15:16:12.219143Z","shell.execute_reply":"2021-11-18T15:16:12.546169Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Os outliers podem ter uma grande influência nos modelos de regressão linear: uma vez que a regressão trata da minimização dos resíduos quadrados, os grandes resíduos têm uma influência desproporcionalmente grande no modelo. Assim, é preciso ter cuidados com os outliers e em alguns casos usamos métodos para a remoçao deles. Vamos acrescentar um outliers - um carro super pesado e eficiente em termos de combustível - e traçar um novo modelo de regressão:","metadata":{}},{"cell_type":"code","source":"mtcars_subset = mtcars[[\"mpg\",\"wt\"]]\n\nsuper_car = pd.DataFrame({\"mpg\" : 50, \"wt\":10}, index = [\"super\"])\n\nnew_cars = mtcars_subset.append(super_car)\n\n\nregression_model = linear_model.LinearRegression()\nregression_model.fit(X = pd.DataFrame(new_cars[\"wt\"]), \n                     y = new_cars[\"mpg\"])\n\ntrain_prediction2 = regression_model.predict(X = pd.DataFrame(new_cars[\"wt\"]))\n\nnew_cars.plot(kind = \"scatter\",\n             x = 'wt',\n             y = 'mpg',\n             color = \"black\",\n             figsize = (9,9),\n             xlim = (1,11), ylim = (10,52))\n\nplt.plot(new_cars[\"wt\"], train_prediction2, color = \"blue\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T15:40:09.195058Z","iopub.execute_input":"2021-11-18T15:40:09.195375Z","iopub.status.idle":"2021-11-18T15:40:09.492469Z","shell.execute_reply.started":"2021-11-18T15:40:09.195343Z","shell.execute_reply":"2021-11-18T15:40:09.491047Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"Neste plot, podemos ver como um único outiliers pode estragar totalmente o modelo. Claro que este é um outilier extremo e pelo plot poderiamos removelo e voltar a um bom modelo.\n\nNum modelo de regressão linear bem comportado, gostaríamos que os resíduos fossem distribuídos de forma mais ou menos normal. Ou seja, gostaríamos de uma distribuição de erros fosse mais ou menos uniforme acima e abaixo da linha de regressão. Podemos investigar a normalidade dos resíduos com um gráfico Q-Q (quantile-quantile). ","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (9,9))\nstats.probplot(residuals, dist = \"norm\", plot = plt)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T15:54:50.642496Z","iopub.execute_input":"2021-11-18T15:54:50.642833Z","iopub.status.idle":"2021-11-18T15:54:50.947205Z","shell.execute_reply.started":"2021-11-18T15:54:50.642803Z","shell.execute_reply":"2021-11-18T15:54:50.946275Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"Quando os resíduos são normalmente distribuídos, tendem a se concentrar ao longo da linha reta na plot Q-Q. Neste caso, os resíduos parecem seguir um padrão um pouco não linear: os resíduos são curvados um pouco para longe da linha de normalidade em cada extremidade. Isto é uma indicação de que uma simples linha reta pode não ser suficiente para descrever completamente a relação entre peso e mpg.","metadata":{}}]}