{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hypothesis Testing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Pontos estimados e intervalo de confiança são ferramentas básicas de inferência, estas funcionam como fundamentos para outras tecnicas de inferência: Statistical Hypothesis Testing (SHT). SHT é um ferramental para determinar se os dados observados desviam dos experados. Sendo baseados na hipótese nula que assume que não há relação entre dois fenômenos medidos. Muitas vezes a hipótese nula é uma afirmação sobre algum parâmetro que é uma propriedade estatística de uma população. A forma exata da hipótese nula varia de um tipo de teste para outro. Por exemplo, se testamos se grupos se diferem, a hipótese nula pode ser: grupos são iguais. No exemplo de dados que estamos lidando, poderia querer testar se a idade média dos vontantes no seu estado se difere da idade média populacional, neste caso, a hipótese nula pode ser: Não existe diferença entre as idades médias.\n\nO objetivo de SHT é determinar se a hipótese nula é verdadeira ou falsa dada uma amostra de dados. Se houver poucos indícios contra a hipótese nula entao aceitamos ela. Caso contrário, podemos rejeitar a hipótese nula a favor a hipótese alternativa: Algo de interessante está acontecendo. \n\nA forma exata da hipótese alternativa dependerá do teste específico. Voltando ao exemplo anterior, a hipótese alternativa seria: A idade média dos eleitores é, de fato, diferente da idade média populacional.\n\n","metadata":{}},{"cell_type":"markdown","source":"Após termos as hipóteses, escolhemos um nível de significancia muitas vezes denotado pela letra alpha que nos dirá quando rejeitar a hipótese nula. Depois de feito o teste, este nos resulta um p-value, que podemos usar para rejeitarmos ou aceitar a hipótese nula. O p-value é é a probabilidade de se obter uma estatística de teste igual ou mais extrema que aquela observada em uma amostra, sob a hipótese nula.  Por exemplo, em testes de hipótese, pode-se rejeitar a hipótese nula a 5% (nível de significancia de 95%) caso o valor-p seja menor que 5%. Assim, uma outra interpretação para o valor-p, é que este é o menor nível de significância com que se rejeitaria a hipótese nula. Em termos gerais, um valor-p pequeno significa que a probabilidade de obter um valor da estatística de teste como o observado é muito improvável, levando assim à rejeição da hipótese nula.","metadata":{}},{"cell_type":"markdown","source":"# One-Sample T-test\n\nUm teste tipo T (Teste t de Student) de uma amostra verifica se a média amostral difere da média populacional da qual a amostra foi retirada. Vamos criar dados de idade fictícios da população votante e uma amostra da idade da população votante em Minnesota, para verificarmos se a média amostral (idade média dos votantes de Minnesota) se difere da média populacional.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport math\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.343973Z","iopub.execute_input":"2021-11-10T17:39:07.344291Z","iopub.status.idle":"2021-11-10T17:39:07.348663Z","shell.execute_reply.started":"2021-11-10T17:39:07.344258Z","shell.execute_reply":"2021-11-10T17:39:07.347773Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"np.random.seed(6)\n\n\npopulation_ages1 = stats.poisson.rvs(loc = 18, mu = 35, size = 150000)\npopulation_ages2 = stats.poisson.rvs(loc = 18, mu = 10, size = 100000)\npopulation_ages = np.concatenate((population_ages1, population_ages2))\n\nminnesota_ages1 = stats.poisson.rvs(loc = 18, mu = 30, size = 30)\nminnesota_ages2 = stats.poisson.rvs(loc = 18, mu = 10, size = 20)\nminnesota_ages = np.concatenate((minnesota_ages1,minnesota_ages2))\n\npopulation_ages.mean(), minnesota_ages.mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.350261Z","iopub.execute_input":"2021-11-10T17:39:07.350736Z","iopub.status.idle":"2021-11-10T17:39:07.406023Z","shell.execute_reply.started":"2021-11-10T17:39:07.350683Z","shell.execute_reply":"2021-11-10T17:39:07.405377Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Vamos realizar um T-test a 95% de nível de confiança e veremos se rejeita corretamente a hipótese nula H0, onde : H0 = A amostra provém da mesma distribuição que a população. ","metadata":{}},{"cell_type":"code","source":"stats.ttest_1samp(a = minnesota_ages, \n                  popmean = population_ages.mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.407239Z","iopub.execute_input":"2021-11-10T17:39:07.407635Z","iopub.status.idle":"2021-11-10T17:39:07.414422Z","shell.execute_reply.started":"2021-11-10T17:39:07.407586Z","shell.execute_reply":"2021-11-10T17:39:07.413543Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Como p-value é de 1.3% podemos rejeitar o hipótese nula neste caso e vemos que de fato os dados amostrais são de uma distribuição distinta da população. O resultado statistic = -2.574 nos diz o quanto a média amostral desvia da população. Se o t-statistics encontra-se fora do range dos quantils definidos pelo nosso nível de confiança (Nível de confiança = 1 - alpha, onde alpha é o nível de significância) podemos rejeitar a hipótese nula.","metadata":{}},{"cell_type":"code","source":"stats.t.ppf(q = 0.025,\n           df = 49), stats.t.ppf(q = 0.975,\n                                df = 49)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.415959Z","iopub.execute_input":"2021-11-10T17:39:07.416260Z","iopub.status.idle":"2021-11-10T17:39:07.426724Z","shell.execute_reply.started":"2021-11-10T17:39:07.416227Z","shell.execute_reply":"2021-11-10T17:39:07.425662Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"E neste caso vemos que de fato o valor statistic resultante do t-test está fora do range.\n\nUm p-value de 0,01311 significa que esperaríamos ver os dados tão extremos como a nossa amostra devido ao acaso, cerca de 1,3% do tempo, se a hipótese nula fosse verdadeira. Neste caso, o vp-value é inferior ao nosso nível de significância alpha (igual a 1-conf.nível ou 0,05), então devemos rejeitar a hipótese nula. Se construíssemos um intervalo de confiança de 95% para a amostra, esta não capturaria a média populacional de 43:\n","metadata":{}},{"cell_type":"code","source":"sigma = minnesota_ages.std()/math.sqrt(50)\n\nstats.t.interval(0.95,\n                df = 49,\n                loc = minnesota_ages.mean(),\n                scale = sigma)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.429686Z","iopub.execute_input":"2021-11-10T17:39:07.430057Z","iopub.status.idle":"2021-11-10T17:39:07.443825Z","shell.execute_reply.started":"2021-11-10T17:39:07.430010Z","shell.execute_reply":"2021-11-10T17:39:07.443169Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"Por outro lado, uma vez que existe uma probabilidade de 1,3% de ver um resultado tão extremo devido ao acaso, este não é significativo ao nível de 99% de confiança. Isto significa que se construíssemos um intervalo de confiança de 99%, isso capturaria a média da população:","metadata":{}},{"cell_type":"code","source":"sigma = minnesota_ages.std()/math.sqrt(50)\nstats.t.interval(0.99,\n                df = 49,\n                loc = minnesota_ages.mean(),\n                scale = sigma)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.445207Z","iopub.execute_input":"2021-11-10T17:39:07.445787Z","iopub.status.idle":"2021-11-10T17:39:07.463882Z","shell.execute_reply.started":"2021-11-10T17:39:07.445747Z","shell.execute_reply":"2021-11-10T17:39:07.463009Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"Com grandes nível de confiança podemos construir um amplo intervalo de confiaça aumentando a chance de capturar a média verdadeira. Contúdo, tornamos menos provável que rejeitemos a hipótese nula. Neste caso, p-value é de 0.013 que é maior que o nosso nível de significancia de 0.01, e portanto, não podemos rejeitar a hipótese nula.","metadata":{}},{"cell_type":"markdown","source":"# Two-Sample T-test","metadata":{}},{"cell_type":"markdown","source":"Um two-sample t-test investiga se as medidas de duas diferentes amostras construídas a partir de dois conjuntos de dados independentes diferem uma da outra. Em um two-sample test a hipótese nula é apresentada considerando que as amostras dos dois grupos são iguais. A função *stats.ttest_ind()* nos permite aplicar tal teste. Vamos construir mais uma amostra populacional e aplicar o teste desta amostra com a de Minnesota:","metadata":{}},{"cell_type":"code","source":"np.random.seed(12)\n\nwinconsin_ages1 = stats.poisson.rvs(loc = 18, mu = 33, size = 30)\nwinconsin_ages2 = stats.poisson.rvs(loc = 18, mu = 13, size = 20)\nwinconsin_ages = np.concatenate((winconsin_ages1, winconsin_ages2))\n\nwinconsin_ages.mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.465137Z","iopub.execute_input":"2021-11-10T17:39:07.465390Z","iopub.status.idle":"2021-11-10T17:39:07.478539Z","shell.execute_reply.started":"2021-11-10T17:39:07.465359Z","shell.execute_reply":"2021-11-10T17:39:07.477831Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"stats.ttest_ind(a = minnesota_ages,\n               b = winconsin_ages,\n               equal_var = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.479610Z","iopub.execute_input":"2021-11-10T17:39:07.480303Z","iopub.status.idle":"2021-11-10T17:39:07.492755Z","shell.execute_reply.started":"2021-11-10T17:39:07.480267Z","shell.execute_reply":"2021-11-10T17:39:07.491789Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"O teste resulta um p-value de 00907 indicando que temos aproximadamente 9% de vermos devido ao acaso dados tão afastados se consideramos que as amostras são identicas. Neste caso, para um nível de confianã de 95% não podemos rejeitar a hipótese nula uma vez que o p-value é maior que 5%.","metadata":{}},{"cell_type":"markdown","source":"# Paired T-Test","metadata":{}},{"cell_type":"markdown","source":"O two-sample t-test é usado para testar duas amostras em grupos diferentes. Em alguns caso, podemos estar interessados a testar diferenças entre amostras de um mesmo grupo em pontos diferentes do tempo. Por exemplo, podemos querer testar se um medicamento para perda de peso funciona, verificando o peso do mesmo grupo de pacientes antes e depois do tratamento. Com um paired t-test podemos vericar se a média de duas amostras de um mesmo grupo difere. \n\nA função *stats.ttest_rel()* te permite performar o teste. Vamos agora gerar os dados dos pacientes e realizar o paired t-test:","metadata":{}},{"cell_type":"code","source":"np.random.seed(11)\n\nbefore = stats.norm.rvs(scale = 30, loc = 250, size = 100)\nafter = before + stats.norm.rvs(scale = 5, loc = -1.25, size = 100)\n\nweight_df = pd.DataFrame({\"weight before\": before,\n                         \"weight after\": after,\n                         \"weight change\": before - after})\nweight_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.494350Z","iopub.execute_input":"2021-11-10T17:39:07.494712Z","iopub.status.idle":"2021-11-10T17:39:07.521362Z","shell.execute_reply.started":"2021-11-10T17:39:07.494666Z","shell.execute_reply":"2021-11-10T17:39:07.520349Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"Os dados estão mostrando que em média os pacientes teve uma perda de peso de 1.23 libras. Vamos conduzir um paired t-test a 95% de nível de confiança para ver se esta diferença é significante. ","metadata":{}},{"cell_type":"code","source":"stats.ttest_rel(a = before,\n               b = after)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T17:39:07.522951Z","iopub.execute_input":"2021-11-10T17:39:07.523270Z","iopub.status.idle":"2021-11-10T17:39:07.530473Z","shell.execute_reply.started":"2021-11-10T17:39:07.523226Z","shell.execute_reply":"2021-11-10T17:39:07.529911Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"Como obtivemos um p-value de 1.15% podemos descartar a hipótese nula (Os dados são equivalentes) e podemos afirmar com 95% de confiança que o remédio aparenta surtir efeitos.","metadata":{}},{"cell_type":"markdown","source":"# Type I and Type II Error","metadata":{}},{"cell_type":"markdown","source":"Existem falhas em Statistical Hypothesis Testing e nas tomadas de decisão (rejeitar ou não rejeitar a hipótese nula). Um teste fornece evidências a favor ou contra a hipótese nula e devemos decidir aceita-la ou reijeita-la. As conclusões incorretas feitas a partir dos hypothesis test são classificadas como dois tipos de erros: Erros do Tipo I e Erros do Tipo II.\n\nErros do Tipo I ocorrem quando rejeitamos a hipótese nula quando esta na verdade é verdadeira, são conhecidos como \"falsos positivos\", pois dizemos que há algo de interessante acontece com os dados quando de fato não há. A taxa de erros do tipoI é igual ao nível de significância alpha, então escolhendo um grande nível de confiança e portanto um pequeno nível de significância faz com que a probabilidade de termos falsos positivos caia.\n\nErros to Tipo II ocorrem quando falhamos em rejeitar a hipótese nula sendo esta falsa. Erros do Tipo II são conhecidos como \"falso negativo\", pois estamos afirmando que não tem nada de diferente nos dados contudo eles são diferentes. Quanto maior o nível de confiança maior é a probabilidade de cometer um erro do Tipo II.\n\nVamos investigar esses erros com um plot:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (12,10))\n\nplt.fill_between( x = np.arange(-4,-2,0.01),\n                y1 = stats.norm.pdf(np.arange(-4,-2,0.01)),\n                facecolor = 'red',\n                alpha = 0.35)\n\nplt.fill_between(x = np.arange(-2,2,0.01),\n                y1 = stats.norm.pdf(np.arange(-2,2,0.01)),\n                facecolor = 'grey',\n                alpha = 0.35)\n\nplt.fill_between(x = np.arange(2,4,0.01),\n                y1 = stats.norm.pdf(np.arange(2,4,0.01)),\n                facecolor = 'red',\n                alpha = 0.35)\n\nplt.fill_between(x = np.arange(-4,-2,0.01),\n                y1 = stats.norm.pdf(np.arange(-4,-2,0.01),loc = 3,scale = 2),\n                facecolor= 'grey',\n                alpha = 0.35)\n\nplt.fill_between(x = np.arange(-2,2,0.01),\n                y1 = stats.norm.pdf(np.arange(-2,2,0.01), loc = 3, scale = 2),\n                facecolor = 'blue',\n                alpha = 0.35)\n\nplt.fill_between(x = np.arange(2,10,0.01),\n                y1 = stats.norm.pdf(np.arange(2,10,0.01), loc = 3, scale =2),\n                 facecolor = 'grey',\n                 alpha = 0.35)\n\nplt.text(x = -2.5, y = 0.01, s = 'Tipe Error I')\nplt.text(x = -0.8, y = 0.20, s = 'Null Hypothesis')\nplt.text(x = 0.3, y = 0.01, s = 'Type Error II')\nplt.text(x = 2.2, y = 0.01, s = 'Type Error I')\nplt.text(x = 3.8, y = 0.08, s = 'Alternative')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:34:47.007054Z","iopub.execute_input":"2021-11-10T18:34:47.007567Z","iopub.status.idle":"2021-11-10T18:34:47.309705Z","shell.execute_reply.started":"2021-11-10T18:34:47.007498Z","shell.execute_reply":"2021-11-10T18:34:47.308922Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"Podemos calcular a taxa de erro de tipo II para as distribuições acima como se segue:","metadata":{}},{"cell_type":"code","source":"lower_quantile = stats.norm.ppf(q = 0.025)\nupper_quantile = stats.norm.ppf(q = 0.975)\n\nlow = stats.norm.cdf(x = lower_quantile,\n                    loc = 3,\n                    scale = 2)\nhigh = stats.norm.cdf(x = upper_quantile,\n                     loc = 3,\n                     scale = 2)\nhigh-low","metadata":{"execution":{"iopub.status.busy":"2021-11-10T18:35:34.690937Z","iopub.execute_input":"2021-11-10T18:35:34.691709Z","iopub.status.idle":"2021-11-10T18:35:34.701953Z","shell.execute_reply.started":"2021-11-10T18:35:34.691668Z","shell.execute_reply":"2021-11-10T18:35:34.700911Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"Assim vemos que com a distribuição normal escolhida a cima, podemos cometor um erro do tipo II aproximadamente 30% das vezes.","metadata":{}},{"cell_type":"markdown","source":"# Statistical Power","metadata":{}},{"cell_type":"markdown","source":"A potência de um teste estatístico é a probabilidade de o teste rejeitar a hipótese nula quando a hipótese alternativa é de facto diferente da hipótese nula. Por outras palavras, o poder é a probabilidade de o teste detectar que se passa algo de interessante quando realmente se passa algo de interessante. A potência (power) é igual a um menos a taxa de erro do tipo II (1-beta). A potência de um teste estatístico é influenciada por:\n1. O nível de significância escolhido\n2. O tamanho amostral\n3. Effect Size.\n\nAo escolher um nível de significância para um teste t há uma troca entre as probabilidade de erros do tipo I e II. Um convenção comum é que um teste estatítico deve ter um potência de 0.8. \n\nUm tamanho maior da amostra reduz a incerteza da estimativa do ponto, fazendo com que a distribuição da amostra se reduza, resultando em taxas de erro de tipo II mais baixas e num aumento da potência.\n\nEffect Size é um termo geral que descreve uma medida numérica do tamanho de algum fenômeno. Existem muitos effect size que surgem dependendo do contexto que estamos. No contexto do t-test um effect size que podemos considerar é a diferença entre duas médias amostrais.  Este número pode ser padronizado através da divisão pelo desvio padrão da população (sigma) ou pelo desvio padrão combinado das amostras. Isto coloca o effect size em termos do desvio padrão, então um effect size padronizado de 0.5 poderia ser interpretado como uma amostra sendo 0.5sigma da outra ( Em geral 0.5 é considerado um effect size grande).\n\nComo a potência estatística, nível de significância, effect size e o tamanho da amostra estão relacionados é possível calcular um deles para obter os outros três. Por exemplo, suponha que temos alpha padrão ( alpha = 0.05), potência padrão (0.8) e digamos que temos um effect size de 0.5 (padronizado) então podemos calcular o tamanho amostral para se obter estes valores.\n\nA biblioteca *statsmodels* nos auxiliam a resolver estes problemas. As funções *statsmodels.stats.power.tt_solve_power* e *statsmodels.stats.power.tt_ind_solve_power* são usadas para os one sample t-test e two sample t-test respectivamente.\n","metadata":{}},{"cell_type":"code","source":"from statsmodels.stats.power import tt_solve_power\ntt_solve_power(effect_size = 0.5,\n               alpha = 0.05,\n               power = 0.8)","metadata":{"execution":{"iopub.status.busy":"2021-11-10T19:11:22.154003Z","iopub.execute_input":"2021-11-10T19:11:22.154487Z","iopub.status.idle":"2021-11-10T19:11:22.166684Z","shell.execute_reply.started":"2021-11-10T19:11:22.154434Z","shell.execute_reply":"2021-11-10T19:11:22.165997Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"Neste caso, queremos um tamanho amostra de pelo menos 34 unidades para poder realizar os t-test com essas características.","metadata":{}}]}